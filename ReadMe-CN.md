# ğŸš€ **vLLM.rs** â€“ ç”¨ Rust å®ç°çš„æç®€ vLLM

ä¸€ä¸ªæé€Ÿ âš¡ã€è½»é‡çš„ ğŸ¦€**Rust å®ç°ç‰ˆ vLLM**ã€‚

---

<p align="center">
  <a href="./ReadMe.md">English</a> |
  <a href="./ReadMe-CN.md">ç®€ä½“ä¸­æ–‡</a>
</p>

## âœ¨ ä¸»è¦ç‰¹æ€§

* ğŸ”§ **çº¯ Rust åç«¯** â€“ å®Œå…¨**ä¸ä¾èµ– PyTorch**
* ğŸš€ **é«˜æ€§èƒ½** (æ”¯æŒ**å‰ç¼€ç¼“å­˜ã€PDåˆ†ç¦»**)
* ğŸ§  **æç®€æ ¸å¿ƒ** â€“ æ ¸å¿ƒé€»è¾‘ä»… **<3000 è¡Œ** Rust ä»£ç 
* ğŸ’» **è·¨å¹³å°æ”¯æŒ** â€“ æ”¯æŒ **CUDA**ï¼ˆLinux/Windowsï¼‰ä¸ **Metal**ï¼ˆmacOSï¼‰
* ğŸ¤– **å†…ç½®API æœåŠ¡ä¸ChatGPTé£æ ¼ç½‘é¡µ** â€“ Rust åŸç”Ÿå®ç°çš„èŠå¤©ä¸ API/Web æœåŠ¡
* ğŸ”Œ **MCPé›†æˆ** â€“ Model Context Protocol å·¥å…·è°ƒç”¨æ”¯æŒ
* ğŸ“Š **Embeddingä¸åˆ†è¯å™¨API** â€“ å®Œæ•´çš„æ–‡æœ¬å¤„ç†æ”¯æŒ
* ğŸ **è½»é‡ Python æ¥å£** â€“ ä½¿ç”¨ PyO3 æ„å»ºçš„ Python èŠå¤©æ¥å£

---

## ğŸ“ˆ æ€§èƒ½

### ğŸ’¬ å¯¹è¯æ€§èƒ½

> **A100** (å•å¡, 40G)

| æ¨¡å‹ | æ ¼å¼ | å¤§å° | è¾“å‡ºé€Ÿåº¦ |
|------------------|---------------|----------|------------------------|
| Ministral-3-3B (Multimodal) | BF16 | 3B | **118.49** tokens/s |
| Ministral-3-3B (Multimodal) | ISQ (BF16->Q4K) | 3B | **171.92** tokens/s |
| Qwen3-VL-8B-Instruct (**Multimodal**) | Q8_0 | 8B | **105.31** tokens/s |
| Llama-3.1-8B | ISQ (BF16->Q4K) | 8B | **120.74** tokens/s |
| DeepSeek-R1-Distill-Llama-8B | Q2_K | 8B | **126.89** tokens/s |
| DeepSeek-R1-0528-Qwen3-8B | Q4_K_M | 8B | **124.87** tokens/s |
| GLM-4-9B-0414 | Q4_K_M | 9B | **70.38** tokens/s |
| QwQ-32B | Q4_K_M | 32B | **41.36** tokens/s |
| **Qwen3-30B-A3B** | Q4_K_M | **30B (MoE)**| **97.16** tokens/s  |

> vLLM.rs åœ¨ **Metal (Apple Silicon, M4)** ä¸Šçš„æ€§èƒ½

  <details>

   | æ¨¡å‹ | å¹¶å‘æ•° | è¾“å‡ºTokens | è€—æ—¶ (s) | ååé‡ (tokens/s) |
   |------------------|--------|--------|---------|-------------|
   | Qwen3-0.6B (BF16) |  128  | 63488       | 83.13s    | 763.73     |
   | Qwen3-0.6B (BF16) |  32      | 15872       | 23.53s    | 674.43    |
   | Qwen3-0.6B (BF16) | 1       | 456       | 9.23s    | 49.42       |
   | Qwen3-4B (Q4_K_M)  | 1       | 1683       | 52.62s    | 31.98     |
   | Qwen3-8B (Q2_K)  | 1       | 1300       | 80.88s    | 16.07     |
  </details>

æŸ¥çœ‹ [**å®Œæ•´æ€§èƒ½æµ‹è¯• â†’**](docs/performance.md)

## ğŸ§  æ”¯æŒçš„æ¨¡å‹æ¶æ„

* âœ… LLaMa ç³»åˆ—ï¼ˆLLaMa2ã€LLaMa3, IQuest-Coderï¼‰
* âœ… Qwen ç³»åˆ—ï¼ˆQwen2ã€Qwen3ï¼‰ï¼ˆæ”¯æŒç¡¬ä»¶FP8åŠ é€Ÿï¼ŒSM90+ï¼‰
* âœ… Qwen2/Qwen3 Moe ç³»åˆ—ï¼ˆæ”¯æŒç¡¬ä»¶FP8åŠ é€Ÿï¼ŒSM90+ï¼‰
* âœ… Mistral v1, v2
* âœ… Mistral-3 VL Reasoning (3B, 8B, 14B, å¤šæ¨¡æ€)
* âœ… GLM4 (0414ç‰ˆæœ¬, **éChatGLM**)
* âœ… GLM4 MoE (4.6/4.7)
* âœ… Phi3 / Phi4 (Phi-3, Phi-4, Phi-4-miniç­‰)
* âœ… Gemma3 (å¤šæ¨¡æ€ï¼Œä¸æ”¯æŒFlash Attention)
* âœ… Qwen3-VL (Dense, å¤šæ¨¡æ€)
* âœ… MiroThinker-v1.5 (30B, 235B)

æ”¯æŒ **Safetensor** (åŒ…å«GPTQ, AWQé‡åŒ–æ ¼å¼) å’Œ **GGUF** æ ¼å¼ã€‚

æ‰€æœ‰æ¨¡å‹å‡æ”¯æŒç¡¬ä»¶FP8 KvCacheåŠ é€Ÿï¼ˆéœ€SM90+åŠå…³é—­`flash-context`ç‰¹æ€§ï¼‰ã€‚

---
## ğŸ“š æ–‡æ¡£
- [å¿«é€Ÿå¼€å§‹](docs/get_started.md)
- [Dockeræ„å»º](docs/docker.md)
- [å·¥å…·è°ƒç”¨è§£æ](docs/tool_parsing.md)
- [MCPé›†æˆä¸å·¥å…·è°ƒç”¨](docs/mcp_tool_calling.md)
- [Claude Codeä½¿ç”¨vLLM.rsåç«¯](docs/claude_code.md)
- [Goose AI Agentä½¿ç”¨vLLM.rsåç«¯](docs/goose.md)
- [Embedding](docs/embeddings.md)
- [å¤šæ¨¡æ€ (Qwen3-VL, Gemma3, Mistral3-VL)](docs/multimodal.md)
- [å‰ç¼€ç¼“å­˜](docs/prefix-cache.md)
- [Ruståº“](docs/rust_crate.md)
- [Tokenize/Detokenize](docs/tokenize.md)
- [æ€§èƒ½æµ‹è¯•](docs/performance.md)


## ğŸ“˜ ä½¿ç”¨æ–¹æ³•ï¼ˆPythonï¼‰
### ğŸ“¦ ä½¿ç”¨ pip å®‰è£…
- ğŸ’¡ **CUDA è®¡ç®—èƒ½åŠ› < 8.0**ï¼ˆä¾‹å¦‚ V100ï¼‰éœ€è¦**æ‰‹åŠ¨ç¼–è¯‘** ï¼ˆä¸æ”¯æŒ `flash-attn`ï¼›æˆ–å¯ä½¿ç”¨ **Rust æ¨¡å¼**ï¼‰ã€‚
- ğŸ’¡ **é¢„ç¼–è¯‘åŒ…** é»˜è®¤å¯ç”¨äº†`flash-context` ç‰¹æ€§ï¼Œè‹¥ä½¿ç”¨ **FP8 KV Cache**ï¼Œé¡»ç§»é™¤ `flash-context`åæ‰‹åŠ¨ç¼–è¯‘ã€‚

> ğŸ Metalï¼ˆmacOSï¼‰
```shell
python3 -m pip install vllm_rs
````

> ğŸŸ© CUDAï¼ˆLinuxï¼‰

#### Ampere / Adaï¼ˆSM80+ï¼‰

```shell
#ï¼ˆå¯é€‰ï¼‰å®‰è£… NCCL
apt-get install -y libnccl2 libnccl-dev
python3 -m pip install vllm_rs
```

#### Hopperï¼ˆSM90+ï¼‰/ Blackwellï¼ˆSM120+ï¼‰

ä» [Release Assets](https://github.com/guoqingbao/vllm.rs/releases/tag/v0.8.7) ä¸‹è½½ wheelï¼Œè§£å‹åå®‰è£… `.whl` åŒ…ã€‚


### ğŸŒâœ¨ API Server + ChatGPTé£æ ¼å†…ç½®ç½‘é¡µ
   ğŸ’¡ä½¿ç”¨`--ui-server`ä¼šåŒæ—¶å¯åŠ¨ChatGPTé£æ ¼ç½‘é¡µ, æ­¤æ—¶æ— éœ€å…¶å®ƒå®¢æˆ·ç«¯ã€‚

   ğŸ’¡å¦‚é•¿æ–‡æœ¬è¯·æ±‚å¯¼è‡´å½“å‰ç”Ÿæˆè¿‡ç¨‹å¡é¡¿ï¼Œè¯·ä½¿ç”¨ **Rust PD Server**æ–¹æ¡ˆ ï¼ˆè§**PDåˆ†ç¦»**ï¼‰

   ğŸ’¡å‰ç¼€ç¼“å­˜ä¸ºè‡ªåŠ¨åŒ¹é…å…¬å…±å‰ç¼€ï¼Œæ— éœ€ `session_id`ã€‚

  <details open>
    <summary>å•å¡ + GGUFæ¨¡å‹</summary>

  ```bash
  # CUDA
  python3 -m vllm_rs.server --m unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF --f Qwen3-30B-A3B-Instruct-2507-Q4_K_M.gguf --kv-fraction 0.7 --ui-server --prefix-cache
  # Metal/MacOS (MacOS Tahoeä¹‹å‰çš„ç³»ç»Ÿå¯èƒ½ä¼šå­˜åœ¨ç”Ÿæˆè¿‡æ…¢é—®é¢˜)
  python3 -m vllm_rs.server --m unsloth/Qwen3-4B-GGUF --f Qwen3-4B-Q4_K_M.gguf --ui-server --max-model-len 32768 --prefix-cache
   ```
  </details>

   <details open>
    <summary>å¤šå¡ + æœ¬åœ°GGUFæ¨¡å‹</summary>

   ```bash
   python3 -m vllm_rs.server --f /path/Qwen3-30B-A3B-Instruct-2507-Q4_K_M.gguf --d 0,1 --ui-server --prefix-cache
   ```
  </details>

  </details>

   <details open>
    <summary>å°†æœªé‡åŒ–æ¨¡å‹åŠ è½½ä¸ºGGUFæ¨¡å‹</summary>

   ```bash
   # åŒæ—¶å°†æƒé‡é‡åŒ–ä¸ºQ4Kæ ¼å¼ï¼Œå¯ç”¨æœ€é•¿ä¸Šä¸‹æ–‡ï¼š
   python3 -m vllm_rs.server --w /path/Qwen3-30B-A3B-Instruct-2507 --isq q4k --d 0,1 --port 8000 --max-model-len 262144 --max-num-seqs 1 --ui-server --prefix-cache
   ```
  </details>


  <details open>
    <summary>FP8æ¨¡å‹</summary>

```bash
# CUDA (MoE, Dense) sm90+ è®¾å¤‡éœ€æ‰“å¼€`cutlass`ç‰¹æ€§ä»¥æ”¯æŒFP8ç¡¬ä»¶åŠ é€Ÿ
vllm-rs --w /path/Qwen3-Coder-30B-A3B-Instruct-FP8 --ui-server --prefix-cache
# MacOS/Metal (Dense)
vllm-rs --m Qwen/Qwen3-4B-Instruct-2507-FP8 --ui-server --prefix-cache
```

  </details>

<details open>
    <summary>å¤šæ¨¡æ€æ¨¡å‹ (Qwen3 VL, +å›¾ç‰‡)</summary>

```bash
# ä½¿ç”¨å†…ç½®ChatUIä¸Šä¼ æˆ–æåŠå›¾ç‰‡url (æ ¼å¼ '.bmp', '.gif', '.jpeg', '.png', '.tiff', or '.webp')
python3 -m vllm_rs.server --m Qwen/Qwen3-VL-8B-Instruct --ui-server --prefix-cache
```

  <details>
    <summary>è¿è¡ŒGPTQ/AWQ Marlinå…¼å®¹æ¨¡å‹</summary>

```bash
python3 -m vllm_rs.server --w /home/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4-Marlin
```
  </details>

æŸ¥çœ‹ [**æ›´å¤šPythonç¤ºä¾‹ â†’**](python/ReadMe.md)



## ğŸ“˜ ä½¿ç”¨æ–¹æ³•ï¼ˆRustï¼‰

### CUDAå¹³å°å®‰è£… (CUDA 11+, 12+, 13.0)

> æ–¹æ¡ˆ 1ï¼šå®‰è£…è¿›Dockerï¼š
   <details>

```bash
cd vllm.rs
# ä½¿ç”¨ä»¥ä¸‹æ„å»ºæ–¹å¼ä¹‹ä¸€

# å°† `sm_80` æ›´æ”¹è‡³ä½ å½“å‰çš„ç¡¬ä»¶ç‰¹æ€§ï¼Œå¦‚ sm_75 (V100), sm_80 (A100), sm_90 (Hopper), sm_100/sm_120 (Blackwell)
./build_docker.sh "cuda,nccl,graph,flash-attn,flash-context,python" sm_80

# æ·»åŠ  `cutlass` ç‰¹æ€§ä»¥æ”¯æŒfp8æ¨¡å‹ (Qwen3ç³»åˆ—, sm90+)ï¼Œä½¿ç”¨CUDA 13 é•œåƒ
./build_docker.sh "cuda,nccl,graph,flash-attn,flash-context,cutlass,python" sm_90 13.0.0

# #ä¼  1 å¯ç”¨Rustä¸­å›½åŒºé•œåƒï¼ˆé€‚ç”¨äºä¸­å›½å¤§é™†ï¼‰
./build_docker.sh "cuda,nccl,graph,flash-attn,flash-context,python" sm_80 12.9.0 1

# ä¼ å…¥ `--prod` ä»¥æ„å»ºç”Ÿäº§é•œåƒï¼ˆä½¿ç”¨ `Dockerfile.prod`ï¼‰
./build_docker.sh --prod "cuda,nccl,graph,flash-attn,flash-context,cutlass,python" sm_90 13.0.0

# æ–°å¢ï¼ˆä½¿ç”¨FlashInferåç«¯ï¼‰
./build_docker.sh "cuda,nccl,flashinfer,python" sm_80
```
   </details>

å‚è€ƒ [**å¦‚ä½•é€šè¿‡Dockerè¿è¡Œ vLLM.rs æœåŠ¡ â†’**](docs/docker.md)

> æ–¹æ¡ˆ 2ï¼šæ‰‹åŠ¨å®‰è£…ï¼š

   <details open>

å®‰è£… Rust å·¥å…·é“¾
```sh
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

å®‰è£…æ„å»ºä¾èµ–ï¼š
```sh
sudo apt-get update
sudo apt-get install -y git build-essential libssl-dev pkg-config
```

å®‰è£… CUDA Toolkitï¼š
```sh
# CUDA 12.9
apt-get update
apt-get install -y \
  cuda-nvcc-12-9 \
  cuda-nvrtc-dev-12-9 \
  libcublas-dev-12-9 \
  libcurand-dev-12-9

# NCCL
apt-get install -y libnccl2 libnccl-dev
```
ç¼–è¯‘ vLLM.rs
```shell
# åªæœ‰å•å¡çš„æƒ…å†µä¸‹å»æ‰ `nccl`
# V100åŠè¾ƒè€çš„æœºå‹å»æ‰ `flash-attn,flash-context`
# CUDAä¸‹åªå»æ‰`flash-context`å¯ä½¿ç”¨FP8 KVCache
# æ·»åŠ  `cutlass`ç‰¹æ€§ä»¥æ”¯æŒFP8æ¨¡å‹ (é€‚ç”¨äºsm90+)
# é»˜è®¤å®‰è£…è¿›/usr/local/binï¼Œä½¿ç”¨`--dst`æ›´æ”¹å®‰è£…ç›®å½•
./build.sh --release --features cuda,nccl,graph,flash-attn,flash-context

# æ–°å¢ï¼ˆä½¿ç”¨FlashInferåç«¯ï¼‰
./build.sh --release --features cuda,nccl,flashinfer
```
  </details>

### MacOS/Metalå¹³å°å®‰è£…

å®‰è£… [Xcode å‘½ä»¤è¡Œå·¥å…·](https://mac.install.guide/commandlinetools/)

ä½¿ç”¨`metal`ç‰¹æ€§å®‰è£…
```shell
cargo install --features metal
```

### è¿è¡Œæ–¹å¼

ä½¿ç”¨ `--i` å¯ç”¨äº¤äº’æ¨¡å¼ ğŸ¤–ï¼Œ`--ui-server` æˆ– `--server` å¯ç”¨æœåŠ¡æ¨¡å¼ ğŸŒï¼Œ`--m`æŒ‡å®šHuggingfaceæ¨¡å‹ï¼Œæˆ–`--w` æŒ‡å®šæœ¬åœ°Safetensorsæ¨¡å‹è·¯å¾„ æˆ–`--f` æŒ‡å®šGGUFæ¨¡å‹æ–‡ä»¶ï¼š

> å•å¡/å¤šå¡æ¨ç†
  <details open>
    <summary>å•å¡æ¨ç†</summary>

   ```bash
   # CUDA ï¼ˆå°† `--i`æ›¿æ¢æˆ `--ui-server`åˆ™å¯ç”¨ç½‘é¡µç‰ˆæœ¬ï¼‰
   vllm-rs --d 0,1 -- --i --m unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF --f Qwen3-30B-A3B-Instruct-2507-Q4_K_M.gguf --kv-fraction 0.8
   # Metal/MacOS (MacOS Tahoeä¹‹å‰çš„ç³»ç»Ÿå¯èƒ½ä¼šå­˜åœ¨ç”Ÿæˆè¿‡æ…¢é—®é¢˜ï¼Œä½¿ç”¨æ›´å°çš„`--max-model-len` æˆ– `--kv-fraction`å‡å°‘æ˜¾å­˜å ç”¨)
   vllm-rs --d 0,1 -- --i --m Qwen/Qwen3-4B-GGUF --f Qwen3-4B-Q4_K_M.gguf
   ```
  </details>

  <details open>
    <summary>å¤šå¡æœªé‡åŒ–æ¨¡å‹</summary>

   ```bash
   vllm-rs --d 0,1 --w /path/Qwen3-30B-A3B-Instruct-2507 --ui-server --prefix-cache
   ```
  </details>

  <details open>
    <summary>FP8æ¨¡å‹</summary>

   ```bash
   vllm-rs --d 0,1 --w /path/Qwen3-Coder-30B-A3B-Instruct-FP8/ --ui-server --prefix-cache
   ```
  </details>

   <details open>
    <summary>å¤šå¡é‡åŒ–æ¨¡å‹</summary>

   ```bash
   vllm-rs --ui-server --d 0,1 --f /path/Qwen3-30B-A3B-Instruct-2507-Q4_K_M.gguf --prefix-cache
   ```
  </details>

   <details open>
    <summary>æœªé‡åŒ–æ¨¡å‹è¿è¡Œä¸ºQ4Ké‡åŒ–æ¨¡å‹ï¼ŒåŒæ—¶ä½¿ç”¨FP8 KVCache</summary>

   ```bash
   # ç¼–è¯‘æ—¶å»é™¤`flash-context`ä»¥ä½¿ç”¨fp8 kvcache
   vllm-rs --d 0,1 --w /path/Qwen3-30B-A3B-Instruct-2507 --isq q4k --server --port 8000 --fp8-kvcache
   ```
  </details>

---
## ğŸ”Œ MCPé›†æˆ (å·¥å…·è°ƒç”¨)

é€šè¿‡Model Context Protocolè®©LLMè°ƒç”¨å¤–éƒ¨å·¥å…·ã€‚

```bash
python3 -m vllm_rs.server --m unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF --f Qwen3-30B-A3B-Instruct-2507-Q4_K_M.gguf --ui-server --prefix-cache --mcp-config ./mcp.json
```
æŸ¥çœ‹ [**MCPæ–‡æ¡£ â†’**](docs/mcp_tool_calling.md)

---

## ğŸ”€ Prefill-decode åˆ†ç¦»ï¼ˆPDåˆ†ç¦»ï¼‰

  <details>
    <summary>å¯åŠ¨PDæœåŠ¡å™¨</summary>
   Metal/MacOSå¹³å°æˆ–PDæœåŠ¡å™¨ä¸PDå®¢æˆ·ç«¯ä¸åœ¨åŒä¸€OSï¼ŒæœåŠ¡å™¨ä¸å®¢æˆ·ç«¯éœ€è¦åŒæ—¶æŒ‡å®š`--pd-url`ï¼ˆä¾‹å¦‚0.0.0.0:8100ï¼‰

   æ— éœ€æŒ‡å®š`port`ï¼Œå› ä¸ºæ­¤æœåŠ¡å™¨ä¸ç›´æ¥æ¥æ”¶ç”¨æˆ·è¯·æ±‚ï¼ŒKvCacheå¤§å°ç”±`--max-model-len`å’Œ`--max-num-seqs`æ§åˆ¶ã€‚
   ```bash
   # PDæœåŠ¡å™¨ä½¿ç”¨`flash-context`åŠ å¿«å¤„ç†é•¿æ–‡æœ¬prefillï¼ˆPDæœåŠ¡å™¨å¯åŠ¨éé‡åŒ–æ¨¡å‹å¯è·å¾—æœ€ä½³ååç‡ï¼‰
   vllm-rs --d 0,1 --w /path/Qwen3-30B-A3B-Instruct-2507 --pd-server
   ```

   PDæœåŠ¡å™¨è¿˜å¯ä½¿ç”¨é¢„ç¼–è¯‘PythonåŒ…å¯åŠ¨ (ä¾èµ–ï¼špip install vllm_rs)
   ```bash
   python3 -m vllm_rs.server --w /path/Qwen3-30B-A3B-Instruct-2507 --d 0,1 --pd-server
   ```
  </details>

  <details>
    <summary>å¯åŠ¨PDå®¢æˆ·ç«¯</summary>

   ```bash
   vllm-rs --d 2,3 --w /path/Qwen3-30B-A3B-Instruct-2507 --isq q4k --ui-server --port 8000 --pd-client
   ```

  PDå®¢æˆ·ç«¯è¿˜å¯ä½¿ç”¨é¢„ç¼–è¯‘PythonåŒ…å¯åŠ¨ (ä¾èµ–ï¼špip install vllm_rs)
  ```bash
   python3 -m vllm_rs.server --d 2,3 --w /path/Qwen3-30B-A3B-Instruct-2507 --isq q4k --ui-server --port 8000 --pd-client
   ```
  </details>

  <details>
    <summary>å•æœºå¤šä¸ªDockers/å¤šæœºé…ç½®</summary>

   PD Serverä¸Clientå¯åŠ¨æ—¶çš„æ¨¡å‹åŠRankæ•°é‡ï¼ˆå¡æ•°ï¼‰éœ€è¦ä¸€è‡´ï¼Œå¯ä¸ºç›¸åŒæ¨¡å‹çš„ä¸åŒæ ¼å¼ï¼ˆä¾‹å¦‚æœåŠ¡å™¨æœªé‡åŒ–Safetensor, å®¢æˆ·ç«¯GGUFï¼‰
   å¦‚æœæŒ‡å®šäº† `--pd-url`ï¼ˆä¾‹å¦‚ serverç«¯: 0.0.0.0:8100, clientç«¯: server_ip:8100ï¼‰ï¼ŒPD æœåŠ¡å™¨/å®¢æˆ·ç«¯å°†å°è¯•ç»‘å®šæˆ–è¿æ¥åˆ°è¯¥åœ°å€ï¼Œ
   å®¢æˆ·ç«¯å°†å°è¯•ä½¿ç”¨æŒ‡å®šçš„ URL è¿æ¥åˆ°æœåŠ¡å™¨ï¼ˆMetalå¹³å°ä¸æ”¯æŒLocalIPC, å¿…é¡»æä¾›pd-urlï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæœåŠ¡å™¨å’Œå®¢æˆ·ç«¯å¯ä»¥éƒ¨ç½²åœ¨ä¸åŒçš„æœºå™¨ä¸Šã€‚
   å•æœºå¤šå¡ï¼ŒPDæœåŠ¡å™¨ä¸å®¢æˆ·ç«¯è¿è¡Œäºä¸åŒDockerï¼Œéœ€è¦é…ç½®Dockerå¯åŠ¨å‚æ•° `--ipc=host`
  </details>

---

## ğŸ“½ï¸ æ¼”ç¤ºè§†é¢‘

ğŸ‰ è§‚çœ‹é¡¹ç›®è¿è¡Œæ¼”ç¤ºï¼š
<video src="https://github.com/user-attachments/assets/7fc6aa0b-78ac-4323-923f-d761dd12857f" width="1000px"></video>


## ğŸ”¨ ä»æºä»£ç ç¼–è¯‘å®‰è£…ï¼ˆå¯é€‰ï¼‰

> âš ï¸ å¯ç”¨ Flash Attentionï¼ˆCUDAï¼‰æ—¶ï¼Œé¦–æ¬¡ç¼–è¯‘å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚

> âš ï¸ å¯ç”¨ å‰ç¼€ç¼“å­˜æˆ–å¤šGPUæ¨ç†æ—¶ï¼Œéœ€è¦åŒæ—¶ç¼–è¯‘`Runner`ï¼ˆä½¿ç”¨`build.sh`ç¼–è¯‘ æˆ– `run.sh`è¿è¡Œï¼‰

### ğŸ› ï¸ ç¯å¢ƒè¦æ±‚
* æ„å»º Python æ¥å£éœ€å®‰è£… [Maturin](https://github.com/PyO3/maturin)

### ç¼–è¯‘æ­¥éª¤
1. **å®‰è£… Maturin**

```bash
sudo apt install libssl-dev pkg-config -y # ç¼–è¯‘ä¾èµ– (Linux)
pip install maturin
pip install maturin[patchelf]  # Linux/Windows å¹³å°
```

2. **æ„å»º Python åŒ…**

```bash
# Naive CUDA (åªèƒ½ç”¨äºå•å¡æ¨ç†) 
maturin build --release --features cuda,python

# Naive CUDA (+CUDA Graph, å®éªŒé˜¶æ®µ)
maturin build --release --features cuda,graph,python

# CUDA (æ”¯æŒContext-cacheä¸FP8 KV Cacheï¼Œä¸ä½¿ç”¨Flash attention) 
./build.sh --release --features cuda,nccl,python

# CUDA (+Flash attentionï¼Œä»…prefillæ—¶å¯ç”¨) 
./build.sh --release --features cuda,nccl,flash-attn,python

# CUDA (+Flash attentionï¼Œprefill/decodingå‡ä½¿ç”¨Flash attentionï¼Œç¼–è¯‘æ—¶é—´æœ€é•¿) 
./build.sh --release --features cuda,nccl,flash-context,python

# macOSï¼ˆMetal, æ”¯æŒContext-cacheä¸FP8 KV Cacheï¼Œä½†ä¸æ”¯æŒå¤šGPUæ¨ç†ï¼‰
maturin build --release --features metal,python

```

3. **å®‰è£…æ„å»ºå¥½çš„åŒ…ä¸ä¾èµ–**

```bash
pip install target/wheels/vllm_rs-*-cp38-abi3-*.whl --force-reinstall
```


### âš™ï¸ å‘½ä»¤è¡Œå‚æ•°è¯´æ˜

| å‚æ•°          | æè¿°                                     |
| ----------- | -------------------------------------- |
| `--m`       | Hugginfaceæ¨¡å‹ID (ç”¨äºä¸‹è½½)               |
| `--w`       | Safetensoræ¨¡å‹è·¯å¾„           |
| `--f`       | å½“æŒ‡å®šModel IDæ—¶ä¸ºGGUFæ–‡ä»¶åï¼Œæˆ–æœªæŒ‡å®šæ—¶ä¸ºGGUFæœ¬åœ°æ–‡ä»¶è·¯å¾„                 |
| `--d`       | è®¾å¤‡ IDï¼Œä¾‹å¦‚ `--d 0`                       |
| `--max-num-seqs`   | åŒæ—¶å¤„ç†çš„æœ€å¤§è¯·æ±‚æ•°ï¼ˆé»˜è®¤ `32`, macOSå¹³å°ä¸º`8`ï¼‰   |
| `--max-tokens`     | å•æ¬¡æœ€å¤§è¾“å‡º token æ•°ï¼ˆé»˜è®¤ `4096`ï¼Œä¸Šé™ä¸ºæ¨¡å‹æ”¯æŒçš„æœ€å¤§é•¿åº¦ï¼‰ |
| `--batch`     | ä»…ç”¨äºæ€§èƒ½ (å¯ç”¨åä¼šå¿½ç•¥ `max-num-seqs` ä¸ `prompts`) |
| `--prompts` | è¾“å…¥çš„ promptï¼Œå¤šä¸ªä½¿ç”¨ \| åˆ†éš” |
| `--dtype`   | KV ç¼“å­˜æ•°æ®ç±»å‹ï¼š`bf16`ï¼ˆé»˜è®¤ï¼‰ã€`f16` æˆ– `f32`     |
| `--isq`   | å°†æœªé‡åŒ–æ¨¡å‹åŠ è½½ä¸ºGGUFé‡åŒ–æ¨¡å‹ï¼Œå¯é€‰`q2k`, `q4k`  ç­‰   |
| `--temperature`   | é‡‡æ ·æ¸©åº¦ (sampling temperature)ï¼Œæ§åˆ¶è¾“å‡º"éšæœºæ€§/åˆ›é€ æ€§"çš„ä¸€ä¸ªè¶…å‚æ•°ï¼Œä»‹äº0-1ä¹‹é—´  |
| `--top-k`   | top-k æ§åˆ¶æ¨¡å‹åœ¨æ¯ä¸€æ­¥åªä»å‰ k ä¸ªæœ€é«˜æ¦‚ç‡çš„è¯é‡ŒæŒ‘é€‰ï¼Œk è¶Šå° â†’ è¶Šç¨³å®šï¼›k è¶Šå¤§ â†’ è¶Šéšæœº   |
| `--top-p`   | top-p é‡‡æ ·æ ¹æ®æ¦‚ç‡é˜ˆå€¼é€‰æ‹©åŠ¨æ€æ•°é‡çš„å€™é€‰ï¼ŒèŒƒå›´æ˜¯ [0,1]ï¼Œå¸¸ç”¨åœ¨ 0.8 ~ 0.95   |
| `--presence-penalty` | å‡ºç°æƒ©ç½šï¼Œæ§åˆ¶æ¨¡å‹æ˜¯å¦é¿å…å†æ¬¡æåŠ`å·²ç»å‡ºç°è¿‡çš„è¯`ã€‚<br> æ•°å€¼èŒƒå›´ [-2, 2]ï¼Œæ­£å€¼è¶Šå¤§ â†’ è¶Šå€¾å‘å¼•å…¥æ–°è¯æ±‡ï¼›è´Ÿå€¼ â†’ è¶Šå€¾å‘é‡å¤å·²å‡ºç°çš„è¯ |
| `--frequency-penalty` | é¢‘ç‡æƒ©ç½šï¼Œæ§åˆ¶æ¨¡å‹æ˜¯å¦å‡å°‘`é«˜é¢‘é‡å¤è¯`çš„å‡ºç°ã€‚<br> æ•°å€¼èŒƒå›´ [-2, 2]ï¼Œæ­£å€¼è¶Šå¤§ â†’ é‡å¤æ¬¡æ•°è¶Šå¤šçš„è¯æƒ©ç½šè¶Šå¼ºï¼›è´Ÿå€¼ â†’ è¶Šé¼“åŠ±é‡å¤ä½¿ç”¨åŒä¸€è¯ |
| `--server`       | æœåŠ¡æ¨¡å¼ï¼Œé€‚ç”¨äºRust CLIï¼ŒPythonä½¿ç”¨ `python -m vllm.server`        |
| `--fp8-kvcache`       | ä½¿ç”¨FP8 KV Cache (flash-contextæ²¡æœ‰å¯ç”¨æ—¶ç”Ÿæ•ˆ)                 |
| `--cpu-mem-fold`       | CPU KV Cacheå¤§å° (ä¸GPU KV Cacheçš„ç™¾åˆ†æ¯”ï¼Œé»˜è®¤ 0.2ï¼Œå–å€¼0.1 - 10.0)              |
| `--pd-server`       | ä½¿ç”¨PDåˆ†ç¦»æ¨¡å¼æ—¶ï¼ŒæŒ‡å®šå½“å‰å®ä¾‹ä¸ºPDæœåŠ¡å™¨ï¼ˆæ­¤æœåŠ¡å™¨ä»…ç”¨äºPrefillï¼‰            |
| `--pd-client`       | ä½¿ç”¨PDåˆ†ç¦»æ¨¡å¼æ—¶ï¼ŒæŒ‡å®šå½“å‰å®ä¾‹ä¸ºPDå®¢æˆ·ç«¯ï¼ˆæ­¤å®¢æˆ·ç«¯å°†é•¿çš„ä¸Šä¸‹æ–‡Prefillè¯·æ±‚å‘é€ç»™PDæœåŠ¡å™¨å¤„ç†ï¼‰|
| `--pd-url`       |  ä½¿ç”¨PDåˆ†ç¦»æ¨¡å¼æ—¶ï¼ŒPDæœåŠ¡å™¨å®ä¾‹å¦‚æŒ‡å®špd-urlï¼Œåˆ™é€šè¿‡TCP/IPé€šä¿¡ï¼ˆé€‚ç”¨äºPDæœåŠ¡å™¨ä¸å®¢æˆ·ç«¯åœ¨ä¸åŒæœåŠ¡å™¨ï¼‰ |
| `--ui-server`       |  æœåŠ¡æ¨¡å¼: å¯åŠ¨APIæœåŠ¡ï¼ŒåŒæ—¶å¯åŠ¨ChatGPTé£æ ¼çš„å†…ç½®å¯¹è¯ç½‘é¡µæœåŠ¡ |
| `--kv-fraction`       |  ç”¨äºæ§åˆ¶KVCacheä½¿ç”¨é‡ (æ¨¡å‹åŠ è½½åå‰©ä½™å¯ç”¨GPUæ˜¾å­˜çš„ç™¾åˆ†æ¯”) |
| `--prefix-cache`   | å¯ç”¨å‰ç¼€ç¼“å­˜ï¼Œç”¨äºå¤šè½®å¯¹è¯ |
| `--prefix-cache-max-tokens`   | é™åˆ¶å‰ç¼€ç¼“å­˜å¤§å°ï¼ˆæŒ‰ block size å‘ä¸‹å–æ•´ï¼‰ |

### MCPé…ç½®å‚æ•°

| å‚æ•° | æè¿° |
|------|------|
| `--mcp-command` | å•ä¸ªMCPæœåŠ¡å™¨å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ |
| `--mcp-args` | MCPæœåŠ¡å™¨å‚æ•°ï¼ˆé€—å·åˆ†éš”ï¼‰ |
| `--mcp-config` | å¤šä¸ªMCPæœåŠ¡å™¨çš„JSONé…ç½®æ–‡ä»¶è·¯å¾„ |

## ğŸ“Œ é¡¹ç›®çŠ¶æ€

> ğŸš§ **é¡¹ç›®ä»åœ¨ç§¯æå¼€å‘ä¸­ï¼Œæ¥å£ä¸åŠŸèƒ½å¯èƒ½å‘ç”Ÿå˜æ›´ã€‚**

## ğŸ› ï¸ å¼€å‘è®¡åˆ’ï¼ˆTODOï¼‰

* [x] Metal å¹³å°æ”¯æŒæ‰¹é‡æ¨ç†
* [x] æ”¯æŒ GGUF æ ¼å¼
* [x] CUDA å¹³å° Flash Attention æ”¯æŒ
* [x] CUDA Graph
* [x] OpenAI API å…¼å®¹æœåŠ¡å™¨ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
* [x] æŒç»­æ‰¹å¤„ç†
* [x] å¤šå¡å¹¶è¡Œæ¨ç†ï¼ˆSafetensorsæ¨¡å‹ã€GPTQ/AWQåŠGGUFé‡åŒ–æ¨¡å‹ï¼‰
* [x] Metal/macOSå¹³å°Promptå¤„ç†åŠ é€Ÿ
* [x] åˆ†å—é¢„å¡«å……ï¼ˆChunked Prefillï¼‰
* [x] å‰ç¼€ç¼“å­˜ (ä½¿ç”¨`prefix-cache`å‚æ•°)
* [x] ä»Hugginface Hubä¸‹è½½å¹¶åŠ è½½æ¨¡å‹
* [ ] ä»ModelScopeä¸‹è½½å¹¶åŠ è½½ (ä¸­å›½å¤§é™†åœ°åŒº)
* [x] Metal/macOSå¹³å°å‰ç¼€ç¼“å­˜
* [x] FP8 KV Cache (CUDA)
* [x] FP8 KV Cache (Metal)
* [ ] FP8 KV Cache (with Flash-Attn)
* [x] FP8 æ¨¡å‹ (CUDA: MoE, Dense; Metal: Dense)
* [ ] æ”¯æŒæ›´å¤šæ¨¡å‹ç±»å‹ï¼ˆLLaMa 4, Kimi K2 Thinkingç­‰ï¼‰
* [x] CPU KV Cache å¸è½½
* [x] PDï¼ˆPrefill/Decodeï¼‰åˆ†ç¦»ï¼ˆCUDAï¼‰
* [x] PDï¼ˆPrefill/Decodeï¼‰åˆ†ç¦»ï¼ˆMetalï¼‰
* [x] å†…ç½® ChatGPTé£æ ¼ Web ç½‘é¡µæœåŠ¡
* [x] **Embedding API**
* [x] **Tokenize/Detokenize API**
* [x] **MCPé›†æˆä¸å·¥å…·è°ƒç”¨**
* [x] **å…¬å…±å‰ç¼€ç¼“å­˜**
* [x] **Claude/Anthropic API å…¼å®¹æœåŠ¡å™¨**
* [x] **æ”¯æŒCUDA 13**
* [x] **æ”¯æŒFlashInferåç«¯**

## ğŸ“š å‚è€ƒé¡¹ç›®

å‚è€ƒï¼š

* [Candle-vLLM](https://github.com/EricLBuehler/candle-vllm)
* Python nano-vllm é¡¹ç›®

---

ğŸ’¡ **å–œæ¬¢è¿™ä¸ªé¡¹ç›®ï¼Ÿæ¬¢è¿ â­ æ”¶è—å’Œå‚ä¸è´¡çŒ®ï¼**
